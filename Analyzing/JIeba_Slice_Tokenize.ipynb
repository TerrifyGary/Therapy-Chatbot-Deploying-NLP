{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7381a1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/garychen/Documents/Therapy-Chatbot-Deploying-NLP/Analyzing')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "pathlib.Path().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "adbd530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "def jiebaSlice(content,mode):\n",
    "    stopword_set = []\n",
    "    with open('./stopword.txt','r', encoding='utf-8') as stopwords:\n",
    "        for stopword in stopwords:\n",
    "            stopword_set.append(stopword.strip('\\n'))\n",
    "\n",
    "    content = content.strip('\\n')\n",
    "    if mode == \"POSSEG\":\n",
    "        words = pseg.cut(content,use_paddle=True)\n",
    "        slicedWords = []\n",
    "        for word, flag in words:\n",
    "            if word not in stopword_set:\n",
    "                slicedWords.append(word)\n",
    "        return slicedWords\n",
    "    elif mode == \"CUT_HMM\":\n",
    "        seg_list = jieba.cut(content,HMM=True,cut_all=True)\n",
    "        slicedWords = list(seg_list)\n",
    "        return slicedWords\n",
    "    elif mode == \"CUT_FOR_SEARCH\":\n",
    "        seg_list = jieba.cut_for_search(content,HMM=True)\n",
    "        slicedWords = list(seg_list)\n",
    "        return slicedWords\n",
    "    elif mode == \"NORMAL\":\n",
    "        seg_list = jieba.cut_for_search(content)\n",
    "        slicedWords = list(seg_list)\n",
    "        return slicedWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c250e6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSSEG 國家兩廳院發這樣的文，然後就不出意料的出事了\n",
      "['國家', '兩', '廳', '院', '發', '文', '後', '不出', '意料', '出事']\n",
      "CUT_HMM 國家兩廳院發這樣的文，然後就不出意料的出事了\n",
      "['國家', '兩廳', '院發', '這樣', '的', '文', '，', '然後就', '不出', '意料', '的', '出事', '了']\n",
      "CUT_FOR_SEARCH 國家兩廳院發這樣的文，然後就不出意料的出事了\n",
      "['國家', '兩廳', '院發', '這樣', '的', '文', '，', '然後就', '不出', '意料', '的', '出事', '了']\n",
      "NORMAL 國家兩廳院發這樣的文，然後就不出意料的出事了\n",
      "['國家', '兩廳', '院發', '這樣', '的', '文', '，', '然後就', '不出', '意料', '的', '出事', '了']\n"
     ]
    }
   ],
   "source": [
    "modes = ['POSSEG','CUT_HMM', 'CUT_FOR_SEARCH', 'NORMAL']\n",
    "sentences = ['國家兩廳院發這樣的文，然後就不出意料的出事了']\n",
    "for x in modes:\n",
    "    for y in sentences:\n",
    "        print(x,y)\n",
    "        print(jiebaSlice(y,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b46cb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-chinese', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d79fde5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['[CLS]', '下雨', '雨天', '下雨天', '留客', '天留', '我', '不留', '[SEP]'], ['[CLS]', '我', '的', '研究', '生命', '還有', '多少', '年', '[SEP]'], ['[CLS]', '以上', '我們', '展示', '了', '如何', '應用', '中文', '斷詞', '到', '實作', '一個', '簡單', '的', '相似', '歌詞', '推薦', '系統', '[SEP]'], ['[CLS]', '結巴', '對', '於', '新', '詞辨識', '的', '表現', '還算', '不錯', '[SEP]']]\n"
     ]
    }
   ],
   "source": [
    "sentences_tokens = list(map(lambda t: ['[CLS]'] + jiebaSlice(t,'NORMAL') + ['[SEP]'], sentences))\n",
    "print(sentences_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73e0114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences\n",
    "sentences_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, sentences_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a105cfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 101  100  100 ...    0    0    0]\n",
      " [ 101 2769 4638 ...    0    0    0]\n",
      " [ 101  100  100 ...    0    0    0]\n",
      " [ 101  100 2205 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(sentences_tokens_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9258bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
