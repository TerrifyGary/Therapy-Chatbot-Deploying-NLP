{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7381a1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/garychen/Documents/Therapy-Chatbot-Deploying-NLP/Analyzing')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "pathlib.Path().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "adbd530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "def jiebaSlice(content,mode):\n",
    "    stopword_set = []\n",
    "    with open('./stopword.txt','r', encoding='utf-8') as stopwords:\n",
    "        for stopword in stopwords:\n",
    "            stopword_set.append(stopword.strip('\\n'))\n",
    "\n",
    "    content = content.strip('\\n')\n",
    "    if mode == \"POSSEG\":\n",
    "        words = pseg.cut(content,use_paddle=True)\n",
    "        slicedWords = []\n",
    "        for word, flag in words:\n",
    "            if word not in stopword_set:\n",
    "                slicedWords.append(word)\n",
    "        return slicedWords\n",
    "    elif mode == \"CUT_HMM\":\n",
    "        seg_list = jieba.cut(content,HMM=True)\n",
    "        slicedWords = list(seg_list)\n",
    "        return slicedWords\n",
    "    elif mode == \"CUT_FOR_SEARCH\":\n",
    "        seg_list = jieba.cut_for_search(content,HMM=True)\n",
    "        slicedWords = list(seg_list)\n",
    "        return slicedWords\n",
    "    elif mode == \"NORMAL\":\n",
    "        seg_list = jieba.cut_for_search(content)\n",
    "        slicedWords = list(seg_list)\n",
    "        return slicedWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c250e6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSSEG 下雨天留客天留我不留\n",
      "['下雨天', '留客', '天', '留', '不留']\n",
      "POSSEG 我的研究生命還有多少年\n",
      "['研究', '生命', '年']\n",
      "POSSEG 以上我們展示了如何應用中文斷詞到實作一個簡單的相似歌詞推薦系統\n",
      "['以上', '展示', '應用', '中文', '斷', '詞', '實作', '一個', '簡單', '相似', '歌詞', '推薦', '系統']\n",
      "POSSEG 結巴對於新詞辨識的表現還算不錯\n",
      "['結巴', '新', '詞', '辨識', '表現', '還算', '不錯']\n",
      "CUT_HMM 下雨天留客天留我不留\n",
      "['下雨天', '留客', '天留', '我', '不留']\n",
      "CUT_HMM 我的研究生命還有多少年\n",
      "['我', '的', '研究', '生命', '還有', '多少', '年']\n",
      "CUT_HMM 以上我們展示了如何應用中文斷詞到實作一個簡單的相似歌詞推薦系統\n",
      "['以上', '我們', '展示', '了', '如何', '應用', '中文', '斷詞', '到', '實作', '一個', '簡單', '的', '相似', '歌詞', '推薦', '系統']\n",
      "CUT_HMM 結巴對於新詞辨識的表現還算不錯\n",
      "['結巴', '對', '於', '新', '詞辨識', '的', '表現', '還算', '不錯']\n",
      "CUT_FOR_SEARCH 下雨天留客天留我不留\n",
      "['下雨', '雨天', '下雨天', '留客', '天留', '我', '不留']\n",
      "CUT_FOR_SEARCH 我的研究生命還有多少年\n",
      "['我', '的', '研究', '生命', '還有', '多少', '年']\n",
      "CUT_FOR_SEARCH 以上我們展示了如何應用中文斷詞到實作一個簡單的相似歌詞推薦系統\n",
      "['以上', '我們', '展示', '了', '如何', '應用', '中文', '斷詞', '到', '實作', '一個', '簡單', '的', '相似', '歌詞', '推薦', '系統']\n",
      "CUT_FOR_SEARCH 結巴對於新詞辨識的表現還算不錯\n",
      "['結巴', '對', '於', '新', '詞辨識', '的', '表現', '還算', '不錯']\n",
      "NORMAL 下雨天留客天留我不留\n",
      "['下雨', '雨天', '下雨天', '留客', '天留', '我', '不留']\n",
      "NORMAL 我的研究生命還有多少年\n",
      "['我', '的', '研究', '生命', '還有', '多少', '年']\n",
      "NORMAL 以上我們展示了如何應用中文斷詞到實作一個簡單的相似歌詞推薦系統\n",
      "['以上', '我們', '展示', '了', '如何', '應用', '中文', '斷詞', '到', '實作', '一個', '簡單', '的', '相似', '歌詞', '推薦', '系統']\n",
      "NORMAL 結巴對於新詞辨識的表現還算不錯\n",
      "['結巴', '對', '於', '新', '詞辨識', '的', '表現', '還算', '不錯']\n"
     ]
    }
   ],
   "source": [
    "modes = ['POSSEG','CUT_HMM', 'CUT_FOR_SEARCH', 'NORMAL']\n",
    "sentences = ['下雨天留客天留我不留','我的研究生命還有多少年','以上我們展示了如何應用中文斷詞到實作一個簡單的相似歌詞推薦系統','結巴對於新詞辨識的表現還算不錯']\n",
    "for x in modes:\n",
    "    for y in sentences:\n",
    "        print(x,y)\n",
    "        print(jiebaSlice(y,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "daa0f734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-chinese', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e6358f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['[CLS]', '下雨', '雨天', '下雨天', '留客', '天留', '我', '不留', '[SEP]'], ['[CLS]', '我', '的', '研究', '生命', '還有', '多少', '年', '[SEP]'], ['[CLS]', '以上', '我們', '展示', '了', '如何', '應用', '中文', '斷詞', '到', '實作', '一個', '簡單', '的', '相似', '歌詞', '推薦', '系統', '[SEP]'], ['[CLS]', '結巴', '對', '於', '新', '詞辨識', '的', '表現', '還算', '不錯', '[SEP]']]\n"
     ]
    }
   ],
   "source": [
    "sentences_tokens = list(map(lambda t: ['[CLS]'] + jiebaSlice(t,'NORMAL') + ['[SEP]'], sentences))\n",
    "print(sentences_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d8ca99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences\n",
    "sentences_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, sentences_tokens)), maxlen=512, truncating=\"post\", padding=\"post\", dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "91865ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 101  100  100 ...    0    0    0]\n",
      " [ 101 2769 4638 ...    0    0    0]\n",
      " [ 101  100  100 ...    0    0    0]\n",
      " [ 101  100 2205 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(sentences_tokens_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9f7191",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
